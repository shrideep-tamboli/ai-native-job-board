{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Screener Pipeline Demo: Data Science Researcher Role\n",
    "\n",
    "This notebook walks through the **screener pipeline** step-by-step:\n",
    "1. **Extract** — Fetch GitHub repo artifacts (commits, PRs, issues) and normalize them.\n",
    "2. **Evaluate** — Score the candidate's artifacts against a job description using AI (Gemini).\n",
    "\n",
    "**Use case:** Score a GitHub profile for a **Data Science Researcher** role.\n",
    "\n",
    "---\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- **Next.js app running:** In a terminal run `npm run dev` so the API is at `http://localhost:3000`.\n",
    "- **GitHub token:** A Personal Access Token (PAT) with `repo` scope, or complete OAuth in the browser and use the token from the redirect URL.\n",
    "- **Environment:** The app must have `GEMINI_API_KEY` set for the evaluate step.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: imports and base URL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API base: http://localhost:3000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "\n",
    "# Base URL of your Next.js app (default: local dev server)\n",
    "BASE_URL = os.environ.get(\"SCREENER_API_URL\", \"http://localhost:3000\")\n",
    "\n",
    "def api(path):\n",
    "    return f\"{BASE_URL}{path}\"\n",
    "\n",
    "print(f\"API base: {BASE_URL}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: GitHub token\n",
    "\n",
    "You need a GitHub token to call the Extract API.\n",
    "\n",
    "- **Option A (recommended for notebooks):** Create a [Personal Access Token](https://github.com/settings/tokens) with `repo` scope and set it in your environment as `GITHUB_TOKEN`, or paste it below (do not commit).\n",
    "- **Option B:** Open `http://localhost:3000/api/auth/github` in a browser, authorize, then copy the `github_token` from the redirect URL and set it below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GitHub token is set (length = 40 )\n"
     ]
    }
   ],
   "source": [
    "# Set your GitHub token (from env or paste here for testing — do not commit)\n",
    "GITHUB_TOKEN = os.environ.get(\"GITHUB_TOKEN\", \"\")\n",
    "\n",
    "if not GITHUB_TOKEN:\n",
    "    print(\"Set GITHUB_TOKEN in your environment or assign it in this cell.\")\n",
    "else:\n",
    "    print(\"GitHub token is set (length =\", len(GITHUB_TOKEN), \")\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Extract — fetch and normalize repo artifacts\n",
    "\n",
    "We call `POST /api/screener/extract` with a **repo URL** and the **token**. The API returns an **ArtifactBundle** (repo metadata, commits, PRs, issues, activity signals).\n",
    "\n",
    "Use any public repo; for a Data Science researcher you might use a repo with notebooks, Python, or ML code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extract success. ArtifactBundle id: artifact_gz6ovh_mlcsf1ta\n",
      "Repo: eshaanmathakari/blockdawg\n",
      "Commits: 3\n",
      "PRs: 0\n",
      "Issues: 0\n",
      "Activity — commit freq (per week): 0.3\n",
      "Languages: ['Python', 'TypeScript', 'JavaScript', 'Solidity', 'CSS']\n"
     ]
    }
   ],
   "source": [
    "# Example: a candidate's GitHub repo (replace with a real public repo for testing)\n",
    "REPO_URL = \"https://github.com/eshaanmathakari/blockdawg\"  # or e.g. facebook/react, owner/repo\n",
    "\n",
    "response = requests.post(\n",
    "    api(\"/api/screener/extract\"),\n",
    "    json={\n",
    "        \"repoUrl\": REPO_URL,\n",
    "        \"token\": GITHUB_TOKEN,\n",
    "        \"options\": {\n",
    "            \"maxCommits\": 50,\n",
    "            \"sinceDays\": 90,\n",
    "            \"includeIssues\": True,\n",
    "            \"includePRs\": True,\n",
    "        },\n",
    "    },\n",
    "    headers={\"Content-Type\": \"application/json\"},\n",
    "    timeout=120,\n",
    ")\n",
    "\n",
    "if not response.ok:\n",
    "    print(\"Extract failed:\", response.status_code)\n",
    "    print(response.json())\n",
    "else:\n",
    "    out = response.json()\n",
    "    artifact_bundle = out[\"data\"]\n",
    "    print(\"Extract success. ArtifactBundle id:\", artifact_bundle[\"id\"])\n",
    "    print(\"Repo:\", artifact_bundle[\"repoMeta\"][\"fullName\"])\n",
    "    print(\"Commits:\", len(artifact_bundle[\"commits\"]))\n",
    "    print(\"PRs:\", len(artifact_bundle[\"pullRequests\"]))\n",
    "    print(\"Issues:\", len(artifact_bundle[\"issues\"]))\n",
    "    print(\"Activity — commit freq (per week):\", artifact_bundle[\"activitySignals\"][\"commitFrequency\"])\n",
    "    print(\"Languages:\", list(artifact_bundle[\"repoMeta\"][\"languages\"].keys())[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect artifact bundle (optional)\n",
    "\n",
    "Pretty-print a subset of the bundle to understand what the evaluator will see.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Repo meta ===\n",
      "{\n",
      "  \"name\": \"blockdawg\",\n",
      "  \"fullName\": \"eshaanmathakari/blockdawg\",\n",
      "  \"description\": \"a sniffer that helps us retrace scammed txns and scammer's wallets\",\n",
      "  \"languages\": {\n",
      "    \"Python\": 81.5,\n",
      "    \"TypeScript\": 16.2,\n",
      "    \"JavaScript\": 1.7,\n",
      "    \"Solidity\": 0.4,\n",
      "    \"CSS\": 0.2\n",
      "  },\n",
      "  \"stars\": 0,\n",
      "  \"forks\": 0,\n",
      "  \"defaultBranch\": \"main\",\n",
      "  \"createdAt\": \"2025-11-18T22:10:26Z\",\n",
      "  \"updatedAt\": \"2026-01-28T15:51:24Z\"\n",
      "}\n",
      "\n",
      "=== Sample commits (first 3) ===\n",
      "  4cc66a0 | added minor changes to week 1 planned architecture | +251/-50\n",
      "  60358b8 | Initial project setup with backend, frontend, and contracts | +20906/-0\n",
      "  3072df2 | Initial commit | +209/-0\n"
     ]
    }
   ],
   "source": [
    "# Show repo meta and first few commits\n",
    "if response.ok:\n",
    "    bundle = response.json()[\"data\"]\n",
    "    print(\"=== Repo meta ===\")\n",
    "    print(json.dumps(bundle[\"repoMeta\"], indent=2))\n",
    "    print(\"\\n=== Sample commits (first 3) ===\")\n",
    "    for c in bundle[\"commits\"][:3]:\n",
    "        print(f\"  {c['sha'][:7]} | {c['message'][:60]} | +{c['additions']}/-{c['deletions']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Define the job description (Data Science Researcher)\n",
    "\n",
    "We define a **JobDescription** that matches the types expected by the Evaluate API. This one is tailored to a Data Science researcher role.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job: Data Science Researcher at Research Lab\n"
     ]
    }
   ],
   "source": [
    "JOB_DESCRIPTION = {\n",
    "    \"id\": \"job_ds_researcher_001\",\n",
    "    \"title\": \"Data Science Researcher\",\n",
    "    \"company\": \"Research Lab\",\n",
    "    \"description\": \"Conduct research in machine learning and statistical modeling. Publish and present findings; collaborate with product and engineering teams to deploy models.\",\n",
    "    \"requirements\": \"PhD or equivalent in a quantitative field. Strong background in ML (supervised/unsupervised, deep learning). Proficiency in Python, PyTorch or TensorFlow, and SQL. Experience with large-scale data and reproducible research (version control, notebooks).\",\n",
    "    \"dailyTasks\": \"Design experiments, implement and evaluate models, write papers and technical reports, review code and mentor junior researchers.\",\n",
    "    \"expectedOutcomes\": \"Novel methods or improvements documented and published; production-ready models where applicable; clear documentation and reproducibility.\",\n",
    "    \"techStack\": [\"Python\", \"PyTorch\", \"TensorFlow\", \"scikit-learn\", \"SQL\", \"Jupyter\", \"Git\"],\n",
    "    \"experienceLevel\": \"mid to senior\",\n",
    "}\n",
    "\n",
    "print(\"Job:\", JOB_DESCRIPTION[\"title\"], \"at\", JOB_DESCRIPTION[\"company\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Evaluate — score candidate against the job\n",
    "\n",
    "We call `POST /api/screener/evaluate` with the **ArtifactBundle** from Step 2 and the **JobDescription**. The API uses Gemini to analyze the artifacts and produce component scores plus an overall score (0–100) and explanation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation id: eval_artifact_job_ds_r_mlcsg1dt\n",
      "Overall score (0–100): 10\n",
      "Confidence: medium\n",
      "\n",
      "Explanation: The candidate demonstrates foundational Python skills and the ability to set up multi-technology projects, but their limited experience (0.5 years) and focus on initial scaffolding of a blockchain application are a poor fit for a mid-to-senior Data Science Researcher role. There is a significant lack of evidence for core ML expertise, research experience, and collaborative development practices required by the job description.\n",
      "\n",
      "Component scores:\n",
      "  skills_alignment: 10 — The candidate demonstrates intermediate Python skills but lacks evidence of proficiency in core ML frameworks (PyTorch, TensorFlow, scikit-learn), SQL, or experience with large-scale data, which are critical for this role.\n",
      "  code_quality: 15 — While commit messages are clear, the candidate shows poor or no evidence of PR documentation, testing practices, or code review participation, which are crucial for reproducible research and collaborative development in a senior role.\n",
      "  experience_relevance: 5 — The candidate's estimated experience of 0.5 years and focus on initial multi-technology project setup are significantly misaligned with the mid-to-senior level research, publication, and model deployment expectations of this Data Science Researcher role.\n",
      "  work_style: 10 — The candidate's communication is limited to clear commit messages, with no evidence of collaborative work through PRs, issue engagement, or code review participation, which are essential for a research and team-oriented role.\n",
      "\n",
      "Flagged concerns: ['Lack of core ML skills (PyTorch, TensorFlow, scikit-learn)', 'No evidence of SQL or large-scale data experience', 'Limited experience (0.5 years) for a mid-to-senior role', 'No evidence of research, publication, or model deployment', 'Poor collaborative development signals (no PRs, testing, code reviews)', 'Domain mismatch (blockchain/full-stack vs. data science research)', 'No evidence of academic background (PhD/quantitative field)']\n"
     ]
    }
   ],
   "source": [
    "eval_response = requests.post(\n",
    "    api(\"/api/screener/evaluate\"),\n",
    "    json={\n",
    "        \"artifactBundle\": artifact_bundle,\n",
    "        \"jobDescription\": JOB_DESCRIPTION,\n",
    "    },\n",
    "    headers={\"Content-Type\": \"application/json\"},\n",
    "    timeout=120,\n",
    ")\n",
    "\n",
    "if not eval_response.ok:\n",
    "    print(\"Evaluate failed:\", eval_response.status_code)\n",
    "    print(eval_response.json())\n",
    "else:\n",
    "    eval_data = eval_response.json()[\"data\"]\n",
    "    print(\"Evaluation id:\", eval_data[\"id\"])\n",
    "    print(\"Overall score (0–100):\", eval_data[\"overallScore\"])\n",
    "    print(\"Confidence:\", eval_data[\"confidence\"])\n",
    "    print(\"\\nExplanation:\", eval_data[\"explanation\"])\n",
    "    print(\"\\nComponent scores:\")\n",
    "    for cs in eval_data[\"componentScores\"]:\n",
    "        print(f\"  {cs['category']}: {cs['score']} — {cs['reasoning']}\")\n",
    "    if eval_data.get(\"flaggedConcerns\"):\n",
    "        print(\"\\nFlagged concerns:\", eval_data[\"flaggedConcerns\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Full pipeline in one go (optional)\n",
    "\n",
    "You can also run **extract** and **evaluate** back-to-back: first extract, then evaluate with the same bundle and job. Below we re-run both steps and print a summary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_full_pipeline(repo_url: str, token: str, job: dict):\n",
    "    \"\"\"Extract artifacts from repo, then evaluate against job. Returns (artifact_bundle, evaluation).\"\"\"\n",
    "    r1 = requests.post(\n",
    "        api(\"/api/screener/extract\"),\n",
    "        json={\"repoUrl\": repo_url, \"token\": token, \"options\": {\"maxCommits\": 50, \"sinceDays\": 90}},\n",
    "        headers={\"Content-Type\": \"application/json\"},\n",
    "        timeout=120,\n",
    "    )\n",
    "    r1.raise_for_status()\n",
    "    bundle = r1.json()[\"data\"]\n",
    "\n",
    "    r2 = requests.post(\n",
    "        api(\"/api/screener/evaluate\"),\n",
    "        json={\"artifactBundle\": bundle, \"jobDescription\": job},\n",
    "        headers={\"Content-Type\": \"application/json\"},\n",
    "        timeout=120,\n",
    "    )\n",
    "    r2.raise_for_status()\n",
    "    evaluation = r2.json()[\"data\"]\n",
    "    return bundle, evaluation\n",
    "\n",
    "\n",
    "# Uncomment and run to test full pipeline with your repo + token:\n",
    "# bundle, evaluation = run_full_pipeline(REPO_URL, GITHUB_TOKEN, JOB_DESCRIPTION)\n",
    "# print(\"Score:\", evaluation[\"overallScore\"], \"|\", evaluation[\"explanation\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "| Step | API | Input | Output |\n",
    "|------|-----|--------|--------|\n",
    "| 1 | — | GitHub token (env or OAuth) | Token for API calls |\n",
    "| 2 | `POST /api/screener/extract` | `repoUrl`, `token`, `options` | `ArtifactBundle` |\n",
    "| 3 | — | Role description | `JobDescription` dict |\n",
    "| 4 | `POST /api/screener/evaluate` | `artifactBundle`, `jobDescription` | `EvaluationResult` (score, components, explanation) |\n",
    "\n",
    "To test with a **different GitHub profile**, change `REPO_URL` and re-run from Step 2. To test a **different role**, edit `JOB_DESCRIPTION` and re-run from Step 4 (or run the full pipeline).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
